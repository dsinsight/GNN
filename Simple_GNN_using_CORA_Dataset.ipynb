{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6A1MK2TyDTjAa4VFFS9sh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsinsight/GNN/blob/main/Simple_GNN_using_CORA_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simple GNN using CORA Dataset**\n",
        "\n",
        "## **1. Importing Required Libraries**\n",
        "\n",
        "- **torch:** PyTorch library, used for building and training deep learning models.\n",
        "- **torch.nn.functional as F:** Provides useful functions like activation functions (relu, log_softmax), loss functions (nll_loss), and other operations that don't require creating layers explicitly.\n",
        "- **GCNConv:** A Graph Convolution layer from torch_geometric, which is a key component for building Graph Neural Networks (GNNs).\n",
        "- **Planetoid:** A dataset loader from torch_geometric for benchmark datasets like CORA, CiteSeer, and PubMed. These datasets are often used for tasks like node classification on citation networks.\n",
        "- **DataLoader:** A PyTorch Geometric utility to load data in mini-batches, but itâ€™s unused in this particular example.\n"
      ],
      "metadata": {
        "id": "AL4GNJk_2uDM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "22YimDx7im1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdeaf665-6551-4525-e6a9-ec7b03150696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Loading the Dataset**\n",
        "\n",
        "- **dataset = Planetoid(...):** Loads the CORA dataset, which is a citation network where nodes represent papers, and edges represent citation relationships between papers. Each node has features (e.g., the text of the paper) and a label (e.g., the paper's category).\n",
        "- **root='/tmp/Cora':** Specifies where to download/store the dataset locally."
      ],
      "metadata": {
        "id": "PnI3SZUl3i51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Cora dataset (a citation network)\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
      ],
      "metadata": {
        "id": "uBlijW6J3wab"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3. Defining the Graph Convolutional Network (GCN) Model**\n",
        "\n",
        "- **GCN:** A custom class for the Graph Convolutional Network (GCN) model. It inherits from torch.nn.Module.\n",
        "- **GCNConv(dataset.num_features, 16):** The first graph convolution layer, where dataset.num_features refers to the number of input features of each node (e.g., the word embeddings of the paper), and 16 is the number of output channels (hidden units).\n",
        "- **GCNConv(16, dataset.num_classes):** The second graph convolution layer, where the input is the 16 hidden units from the first layer, and the output has the size of dataset.num_classes, which corresponds to the number of paper categories in CORA (i.e., the classification task).\n",
        "\n",
        "##**4. Defining the Forward Pass**\n",
        "\n",
        "- **data.x:** The feature matrix of the graph, where each row represents a node and contains its features.\n",
        "- **data.edge_index:** The edge list that represents the connections between nodes (edges of the graph).\n",
        "- **self.conv1(x, edge_index):** The first graph convolution layer. It aggregates features from neighboring nodes based on the graph structure (defined by edge_index).\n",
        "- **F.relu(x):** Applies the ReLU activation function to introduce non-linearity.\n",
        "- **F.dropout(x, training=self.training):** Applies dropout for regularization to prevent overfitting, only during training.\n",
        "- **self.conv2(x, edge_index):** The second graph convolution layer, which produces the logits for classification.\n",
        "- **F.log_softmax(x, dim=1):** The output of the model is passed through a log softmax function, which is typically used in multi-class classification tasks. It outputs the log-probabilities of each class for each node.\n",
        "\n"
      ],
      "metadata": {
        "id": "GKXX7EsY31Ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
        "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "GewtKzMl36F4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5. Creating the Model, Optimizer, and Loss Function**\n",
        "\n",
        "- **torch.device('cuda'...):** Checks if a GPU is available and sets the device to cuda (GPU) if available, otherwise uses cpu.\n",
        "- **model = GCN().to(device):** Initializes the GCN model and transfers it to the specified device (GPU or CPU).\n",
        "- **data = dataset[0].to(device):** Accesses the first graph object in the dataset (in this case, the CORA citation network) and transfers it to the same device.\n",
        "- **optimizer = torch.optim.Adam(...):** Creates an Adam optimizer with a learning rate of 0.01 and a weight decay of 5e-4 for regularization (used to prevent overfitting)."
      ],
      "metadata": {
        "id": "D0QBgEjV42tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model, define the optimizer and loss function\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN().to(device)\n",
        "data = dataset[0].to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "gVBeuJWR450Q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Training the GNN\n",
        "\n",
        "- **model.train():** Sets the model in training mode (PyTorch has separate behaviors for training and evaluation modes).\n",
        "- **Training Loop:** The model is trained for 200 epochs.\n",
        "  - **optimizer.zero_grad():** Clears the gradients from the previous step.\n",
        "  - **out = model(data):** Forward pass through the GCN model, generating predictions for the graph.\n",
        "  - **F.nll_loss(out[data.train_mask], data.y[data.train_mask]):** Calculates the negative log likelihood loss using only the nodes in the training set (indicated by data.train_mask), comparing the predicted labels (out) and true labels (data.y).\n",
        "  - **loss.backward():** Computes the gradients for the model parameters using backpropagation.\n",
        "  - **optimizer.step():** Updates the model parameters based on the computed gradients."
      ],
      "metadata": {
        "id": "Jh3drtmW5Qu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the GNN\n",
        "model.train()\n",
        "for epoch in range(200):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "JSZXrsgA5UCD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**7. Testing the GNN**\n",
        "\n",
        "- **model.eval():** Puts the model into evaluation mode (disables dropout and other layers that behave differently during training).\n",
        "- **_, pred = model(data).max(dim=1):** Performs a forward pass to get predictions for all nodes in the graph. max(dim=1) extracts the predicted class labels by selecting the class with the highest probability.\n",
        "- **pred[data.test_mask].eq(data.y[data.test_mask]):** Compares the predicted labels (pred) with the actual labels (data.y) for the test set (indicated by data.test_mask).\n",
        "- **correct:** Counts the number of correct predictions.\n",
        "- **accuracy:** Computes the accuracy by dividing the number of correct predictions by the total number of test examples.\n",
        "- **print(f'Accuracy:** {accuracy:.4f}'): Prints the accuracy of the model on the test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "3rFuzPse_bnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the GNN\n",
        "model.eval()\n",
        "_, pred = model(data).max(dim=1)\n",
        "correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
        "accuracy = correct / int(data.test_mask.sum())\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sj__wS3_cxJ",
        "outputId": "94559f51-505c-4623-890e-76cf7272053c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code implements a **Graph Convolutional Network (GCN)** for node classification on the **CORA citation network**. The GCN leverages the graph structure by using graph convolutions, which allow the model to aggregate information from neighboring nodes to improve classification performance. The code includes the steps for loading the data, defining the GCN architecture, training the model, and evaluating its accuracy on the test set."
      ],
      "metadata": {
        "id": "ssCjCOG0_2gv"
      }
    }
  ]
}